<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BrainTumourDetectionAI</title>
    <link rel="icon" href="images/tb.png" type="image/png">
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism-tomorrow.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/components/prism-javascript.min.js"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
</head>
<body>
    <header>
                <!-- GIF Preview -->
                <div class="gif">
                    <img src="images/bttd.png" alt="BrainTumourDetectionAI Website GIF">
                </div>
        
        <div class="github-logo-container">
            <a href="https://github.com/manhamalik/Brain_Tumour_Detection_AI" target="_blank" class="github-btn" aria-label="Visit Project GitHub">
                <i class="fab fa-github"></i>
            </a>
        </div>
        
        <div class="portfolio-btn-container">
            <a href="https://manhamalik.com/" target="_blank" class="portfolio-btn" aria-label="Visit Portfolio">
                <i class="fa fa-briefcase"></i>
            </a>
        </div>
    </header>  

  <!-- Project Overview -->
  <section class="content">
    <div class="container">
        <div class="description top-slide-target">
            <h1>BrainTumourDetectionAI: Accelerating Medical Diagnosis</h1>
            <p>
                Brain Tumour Detection AI is an advanced deep learning project aimed at aiding medical professionals in the early detection of 
                brain tumours using MRI scans. By leveraging state-of-the-art convolutional neural networks (CNNs) and transfer learning with 
                pre-trained models like VGG16, InceptionV3, and ResNet50, the project achieved up to 99% accuracy in classifying MRI images for 
                tumour presence. Integrated with Gradio, it provides a real-time interface for testing, ensuring seamless deployment and reliable
                results across diverse datasets.
            </p>
            <p><strong>Technologies and Tools:</strong></p>
                <ul>
                    <li><strong>Programming:</strong> Python</li>
                    <li><strong>Machine Learning & Deep Learning:</strong> TensorFlow, Keras, VGG16, InceptionV3, ResNet50</li>
                    <li><strong>Data Science & Visualization:</strong> NumPy, Matplotlib, Pandas</li>
                    <li><strong>Image Processing & Computer Vision:</strong> OpenCV</li>
                    <li><strong>Development & Deployment:</strong> Gradio, Google Colab, Kaggle API, GitHub</li>
                </ul>
        </div>
    </div>
  </section>

  <!-- Development Process & Methodologies -->
  <section class="content top-slide-target">
    <div class="container">
        <div class="methodologies">
            <h2>Development Process & Methodologies</h2>
            <h3 class="top-slide-target">Agile & Scrum Methodologies</h3>
            <p class="top-slide-target">
                The development process adhered to Agile principles, organized into iterative sprints focusing on data preprocessing, 
                model development, and evaluation. Scrum practices facilitated tracking progress, conducting regular reviews, and 
                adapting to evolving requirements. This ensured that challenges were promptly addressed, and key features like model
                optimization and real-time testing were effectively prioritized and delivered.
            </p>
            <h3 class="top-slide-target">Testing</h3>
            <p class="top-slide-target">
                <b>1. Cross-Validation:</b> Used to assess the model's ability to generalize to unseen data.
                <br><b>2. Evaluation Metrics:</b> Accuracy, sensitivity, specificity, AUC, and AUROC were calculated to evaluate model performance.
                <br><b>3. Manual Testing:</b> Diverse MRI images were used to manually test the models, ensuring robustness and reliability.
                <br><b>4. Continuous Monitoring:</b> Training logs and graphs were analyzed to detect overfitting and underfitting.
            </p>
        </div>
    </div>
  </section>

  <!-- Design Process -->
  <section class="content">
    <div class="container">
        <!-- User Stories -->
        <h2 class="top-slide-target">Design Process (User Stories, Site Map, Wireframes, Prototype)</h2>
        <div class="explanation-visuals">
            <div class="explanation left">
                <h3>User Stories</h3>
                <p>User stories were developed to prioritize essential user experiences, focusing on medical professionals, researchers, and developers.
                </p>
            </div>
            <div class="visual right">
                <iframe style="border: 1px solid rgba(0, 0, 0, 0.1);" width="600" height="400" src="https://embed.figma.com/design/2lH5mnVR0sfLVjEBxBEmL7/BrainTumourDetectionAI?node-id=184-3207&embed-host=share" allowfullscreen loading="lazy"></iframe>
            </div>
        </div>

        <!-- Data Flow Diagram -->
        <div class="explanation-visuals">
            <div class="visual left">
                <iframe style="border: 1px solid rgba(0, 0, 0, 0.1);" width="600" height="400" src="https://embed.figma.com/design/2lH5mnVR0sfLVjEBxBEmL7/BrainTumourDetectionAI?node-id=186-3225&embed-host=share" allowfullscreen loading="lazy"> </iframe>
            </div>
            <div class="explanation right">
                <h3>Data Flow Diagram</h3>
                <p>
                    The Data Flow Diagram shows the process from MRI image upload to prediction display. Images are input, preprocessed, and used for model training. 
                    Trained models are saved, enabling users to upload images via Gradio for inference. The system then outputs a prediction with confidence scores for easy interpretation.         
                </p>
            </div>
        </div>

        <!-- Wireframes -->
        <div class="explanation-visuals">
            <div class="explanation left">
                <h3>Model Architecture</h3>
                <p>
                    The model architecture combines a custom CNN with transfer learning models (VGG16, InceptionV3, ResNet50) to maximize prediction accuracy. 
                    Custom layers were developed to optimize the models' ability to detect tumours in MRI scans, providing a robust and versatile solution for brain tumour detection.
                </p>
            </div>
            <div class="visual right">
                <iframe style="border: 1px solid rgba(0, 0, 0, 0.1);" width="600" height="400" src="https://embed.figma.com/design/2lH5mnVR0sfLVjEBxBEmL7/BrainTumourDetectionAI?node-id=9426-5&embed-host=share" allowfullscreen loading="lazy"></iframe>
            </div>
        </div>

        <!-- Prototype (Desktop & Mobile) -->
        <div class="explanation-visuals">
            
            
        </div>
    </div>
  </section>

  <!-- Feature Demonstrations (Video Clips) -->
  <section class="content">
    <div class="container">
        <h2 class="top-slide-target">Feature Demonstrations</h2>
        <!-- VGG16 Model -->
        <div class="explanation-visuals">
            <div class="explanation left">
                <h3>VGG16 Model Test</h3>
                <p>
                    Using VGG16 for feature extraction, the AI model processes uploaded MRI images to predict tumour presence, displaying tumour probabilities
                     along with training accuracy and loss graphs. This model achieves a validation accuracy of approximately 98.82%.
                </p>
            </div>
            <div class="visual right">
                <video src="videos/VGG16.mp4" controls width="100%"></video>
            </div>
        </div>

        <!-- ResNet50 Model -->
        <div class="explanation-visuals">
            <div class="visual left">
                <video src="videos/ResNet50.mp4" controls width="100%"></video>
            </div>
            <div class="explanation right">
                <h3>ResNet50 Model Test</h3>
                <p>
                    With ResNet50 as the feature extractor, the model provides confidence scores for tumour prediction after an MRI upload. 
                    Training and validation graphs confirm strong performance, reaching around 98.95% validation accuracy with effective learning.
                </p>
            </div>
        </div>

        <!-- InceptionV3 Model -->
        <div class="explanation-visuals">
            <div class="explanation left">
                <h3>InceptionV3 Model Test</h3>
                <p>
                    This model utilizes InceptionV3 for feature extraction, predicting tumour likelihood from uploaded MRI images. 
                    Training and validation graphs show a validation accuracy of about 96.57%.
                </p>
            </div>
            <div class="visual right">
                <video src="videos/InceptionV3.mp4" controls width="100%"></video>
            </div>
        </div>

        <!-- CNN Model -->
        <div class="explanation-visuals">
            <div class="visual left">
                <video src="videos/CNN.mp4" controls width="100%"></video>
            </div>
            <div class="explanation right">
                <h3>Custom CNN Model Test</h3>
                <p>
                    Built from scratch, the custom CNN model processes MRI images without pre-trained weights, offering high-confidence predictions. 
                    Training and validation graphs indicate robust performance, achieving a validation accuracy of approximately 99.10%.
                </p>
            </div>
        </div>

        <!-- Gradio Interface and Code Walkthrough -->
        <div class="explanation-visuals">
            <div class="explanation left">
                <h3>Gradio Interface and Code Walkthrough</h3>
                <p>
                    This video provides a guided walkthrough of the Google Colab environment, showcasing the code structure, validation loss and accuracy
                     charts, dataset visualizations, and the various models used, including pretrained architectures.
                      It highlights the model training processes and results.
                </p>
            </div>
            <div class="visual right">
                <video src="videos/GGA3.mp4" controls width="100%"></video>
            </div>
        </div>

<!-- Code Highlights -->
<section class="code-highlight-section">
    <h2>Code Highlights</h2>
    <div class="explanation-code-container">
        <div class="explanation left">
            <h3>Data Reorganization Function</h3>
            <h4>Code Snippet: merge_and_move_folders Function</h4>
            <p><b>Challenge:</b>
                Consolidate and reorganize dataset directories while removing duplicates and handling potential naming conflicts.
            <br></br><b>Solution:</b>
            <ul>
                <li>Computed MD5 hashes to identify and skip duplicate files.</li>
                <li>Implemented a renaming mechanism to prevent overwriting files with the same name.</li>
                <li>Automated the merging process to handle multiple directories efficiently.</li>
            </ul>
        </p>
        <p>
            <b>Reflection:</b>
            Effective data organization is foundational for machine learning projects. Automating this step reduced errors and ensured consistency in the dataset.
            </p>
        </div>
        <div class="code-block right" id="CS1-code-snippet">
        </div>
    </div>
</section>

<section class="code-highlight-section">
    <div class="explanation-code-container reverse">
        <div class="explanation right">
            <h3>Custom CNN Model Definition</h3>
            <h4>Code Snippet: make_model Function</h4>
            <p><b>Challenge:</b> Designing a CNN architecture suitable for detecting brain tumours with high accuracy on a limited dataset.
            <br></br><b>Solution:</b>
            <ul>
                <li><strong>Depthwise Separable Convolutions:</strong>Reduced the number of parameters, making the model more efficient.</li>
                <li><strong>Residual Connections:</strong> Improved gradient flow and training stability.</li>
                <li><strong>Regularization:</strong> Used dropout and batch normalization to prevent overfitting.</li>
            </ul>
        </p>
        <p><b>Reflection:</b> Custom architectures can be tailored to specific datasets and tasks, achieving a balance between complexity and performance.
        </p>
        </div>
        <div class="code-block right" id="CS2-code-snippet">
        </div>
    </div>
</section>

<section class="code-highlight-section">
    <div class="explanation-code-container">
        <div class="explanation left">
            <h3>Feature Extraction Function</h3>
            <h4>Code Snippet: extract_features Function</h4>
            <p><strong>Challenge:</strong> Efficiently extract features from large pre-trained models while managing computational resources.</p>
            <p><strong>Solution:</strong></p>
            <ul>
                <li><strong>Batch Processing:</strong> Processed data in batches to prevent memory overflow.</li>
                <li><strong>Caching:</strong> Saved extracted features and labels to disk to avoid redundant computations.</li>
                <li><strong>Conditional Loading:</strong> Implemented checks to load existing features if they were already computed.</li>
            </ul>
            <p><strong>Reflection:</strong> Efficient data handling is crucial when working with large datasets and models. Optimizing this process saved time and computational resources.</p>
        </div>
        <div class="code-block right" id="CS3-code-snippet">
        </div>
    </div>
</section>

<section class="code-highlight-section">
    <h2>Summary Report</h2>
    <embed src="assets/summary-report.pdf" type="application/pdf" width="100%" height=auto tabindex="-1" />

</section>

        <section class="code-highlight-section">
            <h2>Overall Results & Insights</h2>
                        <h3>Performance Summary</h3>
                        <div class="performance-summary">
                            <table>
                                <thead>
                                    <tr>
                                        <th>Model</th>
                                        <th>Training Accuracy</th>
                                        <th>Validation Accuracy</th>
                                        <th>Loss</th>
                                        <th>Val Loss</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td>VGG16 (epoch 24)</td>
                                        <td>99.86%</td>
                                        <td>98.82%</td>
                                        <td>0.025</td>
                                        <td>0.05</td>
                                    </tr>
                                    <tr>
                                        <td>ResNet50 (epoch 24)</td>
                                        <td>99.98%</td>
                                        <td>98.95%</td>
                                        <td>0.018</td>
                                        <td>0.04</td>
                                    </tr>
                                    <tr>
                                        <td>InceptionV3 (epoch 24)</td>
                                        <td>98.86%</td>
                                        <td>96.57%</td>
                                        <td>0.035</td>
                                        <td>0.07</td>
                                    </tr>
                                    <tr>
                                        <td>Custom CNN (epoch 14)</td>
                                        <td>98.98%</td>
                                        <td>99.10%</td>
                                        <td>0.022</td>
                                        <td>0.045</td>
                                    </tr>
                                </tbody>
                            </table>                            
                        </div>
            <h3>Insights</h3>
            <p class="top-slide-target">
                The training and validation accuracy graphs showed consistent improvement over the epochs, with minimal overfitting observed.
                The high validation accuracy and low validation loss for VGG16, ResNet50, and the Custom CNN model indicate their robustness in detecting brain tumours.
            </p>
            <ul>
                <li><b>Model Performance:</b> All models achieved high accuracy, with the Custom CNN slightly outperforming the others in validation accuracy.</li>
                <li><b>Data Augmentation:</b> Significantly improved the models' ability to generalize.</li>
                <li><b>Transfer Learning:</b> Leveraging pre-trained models accelerated training and improved performance.</li>
                <li><b>Gradio Integration:</b> Enhanced accessibility and user engagement with the models.</li>
            </ul>
        </section>
        
      <!-- Conclusion -->
      <section class="code-highlight-section">
                <h2>Conclusion</h2>
                <p class="top-slide-target">
                    BrainTumourDetectionAI demonstrates the effective application of deep learning techniques in medical imaging for early tumour detection. 
                    By utilizing both custom CNN models and transfer learning with pre-trained networks, high accuracy in classifying MRI images for tumour 
                    presence was achieved. Integrating Gradio provided a user-friendly platform for real-time testing, making the AI system accessible to 
                    medical professionals and researchers. This project highlights the importance of data preprocessing, model optimization, and user 
                    interface design in developing AI solutions for healthcare.
                </p>
      </section>
<script>
    // Function to escape HTML special characters
    function escapeHTML(code) {
        return code
            .replace(/&/g, "&amp;")
            .replace(/</g, "&lt;")
            .replace(/>/g, "&gt;")
            .replace(/"/g, "&quot;")
            .replace(/'/g, "&#039;");
    }

    // Function to load and display a code snippet
    function loadCodeSnippet(fileName, elementId) {
        fetch(fileName)
        .then(response => response.text())
        .then(data => {
            const escapedCode = escapeHTML(data);
            document.getElementById(elementId).innerHTML = `<pre><code class="language-js">${escapedCode}</code></pre>`;
            Prism.highlightAll(); // Re-highlight the code after loading
        });
    }

    // Load the JavaScript code snippets for each file
    loadCodeSnippet('code_snippets/CS1.py', 'CS1-code-snippet');
    loadCodeSnippet('code_snippets/CS2.py', 'CS2-code-snippet');
    loadCodeSnippet('code_snippets/CS3.py', 'CS3-code-snippet');
</script>

  <script>
    // animations
    document.addEventListener("DOMContentLoaded", function() {
  const leftExplanations = document.querySelectorAll(".explanation.left");
  const rightExplanations = document.querySelectorAll(".explanation.right");
  const topSlideTargets = document.querySelectorAll(".top-slide-target");

  const observerOptions = {
    threshold: 0.1
  };

  const observer = new IntersectionObserver(function(entries, observer) {
    entries.forEach(entry => {
      if (entry.isIntersecting) {
        if (entry.target.classList.contains("left")) {
          entry.target.classList.add("slide-in-left");
        } else if (entry.target.classList.contains("right")) {
          entry.target.classList.add("slide-in-right");
        } else if (entry.target.classList.contains("top-slide-target")) {
          entry.target.classList.add("slide-in-bottom");
        }
        observer.unobserve(entry.target); // Stop observing once animated
      }
    });
  }, observerOptions);

  leftExplanations.forEach(el => observer.observe(el));
  rightExplanations.forEach(el => observer.observe(el));
  topSlideTargets.forEach(el => observer.observe(el));
});
  </script>

<script>
    // Scroll to the top on page load
    window.addEventListener("load", () => {
      window.scrollTo(0, 0);
    });
  </script>
  
<!-- Footer Section -->
<footer>
    <div class="footer-container">
        <p>&copy; 2024 BrainTumourDetectionAI. All Rights Reserved. | Designed and developed by Manha Malik.</p>
        <div class="social-icons">
            <a href="https://manhamalik.com/" target="_blank"><i class="fa-solid fa-briefcase"></i></a>
            <a href="https://www.linkedin.com/in/manha-m/" target="_blank"><i class="fa-brands fa-linkedin"></i></a>
            <a href="https://github.com/manhamalik?tab=repositories" target="_blank"><i class="fa-brands fa-github-square"></i></a>
            <a href="mailto:info@manhamalik.com" target="_blank"><i class="fa-solid fa-envelope"></i></a>
        </div>
    </div>
</footer>

</body>
</html>
